{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day18 Categorical Data 2/2 counting and feature hashing \n",
    "# 類別型特徵 2/2 計數編碼與特徵雜湊\n",
    "\n",
    "## 計數編碼\n",
    "如果類別型特徵的目標值與類別筆數呈相關，可將筆數本身當作特徵，例如：自然語言處理中，字詞的計數編碼稱為詞頻，是自然語言處理中很重要的特徵。\n",
    "\n",
    "## Counting\n",
    "If the target value of the categorical data and the counting are correlated, we can then use the counting as a feature. For example, in Natural Language Processing, word counts itself is a very important and useful feature.<br>\n",
    "![Title](1801.png)<br>\n",
    "\n",
    "## 特徵雜湊\n",
    "特徵雜湊將類別型特透過徵雜湊函數對應到一組數字，調整雜湊函數控制對應值的數量，在計算成本與鑑別度間取折衷，提高訊息密度並減少無用的標籤。當相異類別數量相當大時可考慮使用雜湊編碼以節省時間。\n",
    "\n",
    "## Feature Hashing\n",
    "Feature hashing is projecting categorical features onto numbers using hash functions. It is a method compromised computational costs and discrimination. Feature hashing could reduce useless labels and increase the density of information of the data. We could consider using it when there are a lot of categorical features to save time.\n",
    "![Title](1802.jpg)<br>\n",
    "\n",
    "\n",
    "\n",
    "文中若有錯誤還望不吝指正，感激不盡。\n",
    "Please let me know if there’s any mistake in this article. Thanks for reading.\n",
    "\n",
    "Reference 參考資料：\n",
    "\n",
    "[1] 第二屆機器學習百日馬拉松內容\n",
    "\n",
    "[2] [Word to Vectors](https://towardsdatascience.com/word-to-vectors-natural-language-processing-b253dd0b0817)\n",
    "\n",
    "[3] [数据特征处理之特征哈希](https://www.datalearner.com/blog/1051537932880901)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
