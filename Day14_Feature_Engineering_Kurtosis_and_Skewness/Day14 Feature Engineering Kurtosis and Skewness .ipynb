{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day14 Feature Engineering, Kurtosis and Skewness \n",
    "# 淺談特徵工程、峰度與偏度\n",
    "\n",
    "特徵工程是把原始資料對應到後續評估分數的轉換過程，是在擬合模型前重要的步驟。常見特徵有：數值型特徵、類別型特徵與時間序列特徵，之後會有文章分別介紹。一般而言，我們取得的資料都會包含類別型(文字型)特徵以及數值型特徵，所以在特徵工程中就會包含進行編碼以及特徵縮放的部分。\n",
    "\n",
    "Feature engineering is the process of turning raw data into features, it is an essencial step before we fit data to models. There are three types of frequently seen features: numeric features, categorical features, and time series features. We will discuss through them in the following articles. Generally, there will be both numeric features categorical features in our data, so we will have to include at least encoding and feature scaling methods in our feature engineering.\n",
    "![Title](1401.png)\n",
    "\n",
    "## 編碼方法 Encoding\n",
    "除了前面文章中提過的編碼方式外，這邊再列出幾種常見的編碼方式。要針對不同的問題類別選擇不同的編碼。\n",
    "1. 獨熱編碼\n",
    "2. 標籤編碼\n",
    "3. 均值編碼\n",
    "4. 目標編碼\n",
    "5. 頻數編碼\n",
    "6. 二值化編碼\n",
    "\n",
    "Some other mothods of encoding are listed as below. We decide which encoding method to use depend on the problem type.\n",
    "1. One-hot encoding\n",
    "2. Label encoding\n",
    "3. Mean encoding\n",
    "4. Target encoding\n",
    "5. Count encoding\n",
    "6. Label binarize encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徵縮放方法 Feature scaling\n",
    "\n",
    "### 歸一化 Scaling to unit length\n",
    "把原始資料縮放到(0,1)的區間內，統一數據的衡量標準以消除單位的影響。Sklearn中最常用的方法是MinMaxScaler。<br>\n",
    "Transit raw data into 0-1 range. The most commonly used method in Sklearn is MinMaxScaler.\n",
    "\n",
    "### 標準化 Normalization\n",
    "把資料按比例縮放到一個限定的區間。但如果資料不遵從高斯正態分布時，標準化表現會比較差。常用的標準化方法有Z-score、StandardScaler等。\n",
    "Normalize data into a specified range. Normalization wouldn't perform so good if the distribution of data is far from normal. Most commonly used methods are z-score normalization, StandardScaler, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 偏度 Skewness\n",
    "資料分布偏斜的方向與程度，分為正態分布(及偏度=0)、右偏分布（正偏分布，偏度>0）、左偏分布（負偏分布，其偏度<0）。<br>\n",
    "Skewness is a measure of the asymmetry of the probability distribution. Could be either symmetric distribution (skewness=0), positive skew (skewness>0), or negative skew (skewness<0).\n",
    "![Title](1401.jpg)\n",
    "\n",
    "## 峰度 Kurtosis\n",
    "衡量分布的峰態。峰度包括正態分布（峰度值=3），厚尾（峰度值>3），瘦尾（峰度值<3）。<br>\n",
    "Kurtosis is a descriptor of the shape of a probability distribution.\n",
    "\n",
    "![Title](1402.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文中若有錯誤還望不吝指正，感激不盡。\n",
    "Please let me know if there’s any mistake in this article. Thanks for reading.\n",
    "\n",
    "Reference 參考資料：\n",
    "\n",
    "[1] 第二屆機器學習百日馬拉松內容\n",
    "\n",
    "[2] [偏度(skewness)和峰度(kurtosis）](https://blog.csdn.net/xbmatrix/article/details/69360167)\n",
    "\n",
    "[3] [特征工程](https://feisky.xyz/machine-learning/basic/feature-engineering.html)\n",
    "\n",
    "[4] [特征工程到底是什么？](https://www.zhihu.com/question/29316149)\n",
    "\n",
    "[5] [一文看懂常用特徵工程方法](https://kknews.cc/code/ek3mvar.html)\n",
    "\n",
    "[6] [特征工程方法：一、类别变量编码](特征工程方法：一、类别变量编码)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
